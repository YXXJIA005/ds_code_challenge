{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "958b27e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # set to DEBUG for more detail\n",
    "    format=\"%(asctime)s | %(levelname)-8s | %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f961b3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing sr.csv...\n",
      "\n",
      "Processing sr_hex.csv...\n",
      "\n",
      "Processing sr_hex_truncated.csv...\n",
      "\n",
      "Processing city-hex-polygons-8.geojson...\n",
      "\n",
      "All files loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# File â†’ variable name mapping\n",
    "file_map = {\n",
    "    \"sr.csv\": \"df_sr\",\n",
    "    \"sr_hex.csv\": \"df_sr_hex\",\n",
    "    \"sr_hex_truncated.csv\": \"df_sr_hex_truncated\",\n",
    "    \"city-hex-polygons-8.geojson\": \"gdf_city_hex_8\"\n",
    "}\n",
    "\n",
    "# Load the files\n",
    "for file_name, var_name in file_map.items():\n",
    "    print(f\"\\nProcessing {file_name}...\")\n",
    "\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        df = pd.read_csv(file_name)\n",
    "        globals()[var_name] = df\n",
    "\n",
    "    elif file_name.endswith(\".geojson\"):\n",
    "        gdf = gpd.read_file(file_name)\n",
    "        globals()[var_name] = gdf\n",
    "\n",
    "print(\"\\nAll files loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4079940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np \n",
    "import h3\n",
    "\n",
    "def assign_h3_level8(\n",
    "    df: pd.DataFrame,\n",
    "    lat_col: str = \"latitude\",\n",
    "    long_col: str = \"longitude\",\n",
    "    threshold: float = 0.05,\n",
    "    resolution: int = 8,\n",
    "    early_abort: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Assigns h3_level 8 based on latitude and longitude.\n",
    "\n",
    "    Logs:\n",
    "      - Row counts and join stats\n",
    "    \"\"\"\n",
    "    # ---- Global timer start + resource snapshot ----\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    if lat_col not in df.columns or long_col not in df.columns:\n",
    "        raise ValueError(f\"DataFrame must have '{lat_col}' and '{long_col}' columns.\")\n",
    "\n",
    "    df_out = df.copy()\n",
    "\n",
    "    # converts lat and long to numpy, and gets failure rate.\n",
    "    v0 = time.perf_counter()\n",
    "    lat = pd.to_numeric(df_out[lat_col], errors=\"coerce\").to_numpy()\n",
    "    long = pd.to_numeric(df_out[long_col], errors=\"coerce\").to_numpy()\n",
    "\n",
    "    valid = (\n",
    "        np.isfinite(lat) & np.isfinite(long) &\n",
    "        (lat >= -90.0) & (lat <= 90.0) &\n",
    "        (long >= -180.0) & (long <= 180.0)\n",
    "    )\n",
    "    n = lat.shape[0]\n",
    "    n_invalid = int((~valid).sum())\n",
    "    fail_rate_pre = (n_invalid / n) if n > 0 else 0.0\n",
    "\n",
    "    if early_abort and fail_rate_pre > threshold:\n",
    "        raise RuntimeError(\n",
    "            f\"Join failure rate {fail_rate_pre:.2%} exceeds threshold {threshold:.2%} \"\n",
    "            f\"(invalid coords: {n_invalid}/{n}) after validation.\"\n",
    "        )\n",
    "\n",
    "    # ---- Phase: H3 compute ----\n",
    "    c0 = time.perf_counter()\n",
    "    out = np.empty(n, dtype=object)\n",
    "    out.fill(\"0\")\n",
    "\n",
    "    if valid.any():\n",
    "        lat_v = lat[valid]\n",
    "        long_v = long[valid]\n",
    "        res = [h3.latlng_to_cell(la, lo, resolution) for la, lo in zip(lat_v, long_v)]\n",
    "        out[valid] = res\n",
    "\n",
    "    # ---- Phase: assign to DataFrame ----\n",
    "    df_out[\"h3_level8_index\"] = out\n",
    "\n",
    "    # ---- Join stats ----\n",
    "    failed = int((df_out[\"h3_level8_index\"] == \"0\").sum())\n",
    "    success = n - failed\n",
    "    fail_rate_post = failed / n if n > 0 else 0.0\n",
    "\n",
    "    logger.debug(\"Total records: %d\", n)\n",
    "    logger.debug(\"Assigned hex IDs: %d\", success)\n",
    "    logger.debug(\"Failed to join: %d (%.2f%%)\", failed, fail_rate_post * 100)\n",
    "\n",
    "    # ---- Timing summary ----\n",
    "    t1 = time.perf_counter()\n",
    "    logger.info(\"Total elapsed: %.3f\", t1 - t0)\n",
    "\n",
    "\n",
    "    # ---- Threshold check ----\n",
    "    if fail_rate_post > threshold:\n",
    "        logger.error(\n",
    "            \"Post-compute failure rate %.2f%% exceeds threshold %.2f%%\",\n",
    "            fail_rate_post * 100,\n",
    "            threshold * 100,\n",
    "        )\n",
    "        raise RuntimeError(\"Too many failed joins\")\n",
    "\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc6bb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compare_h3_by_notification(\n",
    "    df1: pd.DataFrame,\n",
    "    df2: pd.DataFrame,\n",
    "    key: str = \"notification_number\",\n",
    "    col: str = \"h3_level8_index\",\n",
    "    coerce_to_str: bool = True,   # normalize dtypes before compare\n",
    "    na_equal: bool = True,        # treat NaN==NaN as equal\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare df1 vs df2 on a single column (h3_level8_index) by notification key.\n",
    "\n",
    "    Returns dict with:\n",
    "      - only_in_df1: keys present only in df1\n",
    "      - only_in_df2: keys present only in df2\n",
    "      - matches: keys in both where h3 matches (per na_equal rule)\n",
    "      - mismatches: keys in both where h3 differs, with left/right values\n",
    "    \"\"\"\n",
    "    if key not in df1.columns or key not in df2.columns:\n",
    "        raise ValueError(f\"Key '{key}' must exist in both DataFrames.\")\n",
    "    if col not in df1.columns or col not in df2.columns:\n",
    "        raise ValueError(f\"Column '{col}' must exist in both DataFrames.\")\n",
    "\n",
    "    left = df1[[key, col]].copy()\n",
    "    right = df2[[key, col]].copy()\n",
    "\n",
    "    if coerce_to_str:\n",
    "        for d in (left, right):\n",
    "            d[col] = d[col].astype(\"object\").where(d[col].isna(), d[col].astype(str))\n",
    "\n",
    "    merged = left.merge(\n",
    "        right,\n",
    "        on=key,\n",
    "        how=\"outer\",\n",
    "        suffixes=(\"_df1\", \"_df2\"),\n",
    "        indicator=True,\n",
    "    )\n",
    "\n",
    "    only_in_df1 = merged.loc[merged[\"_merge\"] == \"left_only\", [key]]\n",
    "    only_in_df2 = merged.loc[merged[\"_merge\"] == \"right_only\", [key]]\n",
    "\n",
    "    both = merged.loc[merged[\"_merge\"] == \"both\", [key, f\"{col}_df1\", f\"{col}_df2\"]].copy()\n",
    "\n",
    "    lv = both[f\"{col}_df1\"]\n",
    "    rv = both[f\"{col}_df2\"]\n",
    "    equal_mask = (lv == rv)\n",
    "    if na_equal:\n",
    "        equal_mask = equal_mask | (lv.isna() & rv.isna())\n",
    "\n",
    "    matches = both.loc[equal_mask, [key]]\n",
    "    mismatches = both.loc[~equal_mask, [key, f\"{col}_df1\", f\"{col}_df2\"]].rename(\n",
    "        columns={f\"{col}_df1\": f\"{col}_left\", f\"{col}_df2\": f\"{col}_right\"}\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"only_in_df1\": only_in_df1.reset_index(drop=True),\n",
    "        \"only_in_df2\": only_in_df2.reset_index(drop=True),\n",
    "        \"matches\": matches.reset_index(drop=True),\n",
    "        \"mismatches\": mismatches.reset_index(drop=True),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "225f600f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 23:50:59 | INFO     | Total elapsed: 0.591\n"
     ]
    }
   ],
   "source": [
    "df_sr2 = assign_h3_level8(df_sr, lat_col=\"latitude\", long_col=\"longitude\", threshold=0.226)\n",
    "df_sr2.drop(columns=[\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a5341da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only in df1: 0\n",
      "Only in df2: 0\n",
      "Matches    : 941634\n",
      "Mismatches : 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "result = compare_h3_by_notification(df_sr2, df_sr_hex, key=\"notification_number\", col=\"h3_level8_index\")\n",
    "\n",
    "print(\"Only in df1:\", len(result[\"only_in_df1\"]))\n",
    "print(\"Only in df2:\", len(result[\"only_in_df2\"]))\n",
    "print(\"Matches    :\", len(result[\"matches\"]))\n",
    "print(\"Mismatches :\", len(result[\"mismatches\"]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
