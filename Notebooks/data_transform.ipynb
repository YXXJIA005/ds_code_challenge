{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bc0cb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipytest, pytest, pandas as pd\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "958b27e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  \n",
    "    format=\"%(asctime)s | %(levelname)-8s | %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f961b3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 21:30:10 | INFO     | \n",
      "Processing /Users/ben/Documents/test/ds_code_challenge/data/sr.csv...\n",
      "2025-08-19 21:30:12 | INFO     | \n",
      "Processing /Users/ben/Documents/test/ds_code_challenge/data/sr_hex.csv...\n",
      "2025-08-19 21:30:14 | INFO     | \n",
      "Processing /Users/ben/Documents/test/ds_code_challenge/data/sr_hex_truncated.csv...\n",
      "2025-08-19 21:30:14 | INFO     | \n",
      "Processing /Users/ben/Documents/test/ds_code_challenge/data/city-hex-polygons-8.geojson...\n",
      "2025-08-19 21:30:14 | INFO     | All files loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path(__file__).resolve().parents[0] if \"__file__\" in globals() else Path().resolve()\n",
    "while ROOT.name != \"ds_code_challenge\" and ROOT.parent != ROOT:\n",
    "    ROOT = ROOT.parent\n",
    "\n",
    "DATA_DIR = ROOT / \"data\"\n",
    "\n",
    "file_map = {\n",
    "    \"sr.csv\": \"df_sr\",\n",
    "    \"sr_hex.csv\": \"df_sr_hex\",\n",
    "    \"sr_hex_truncated.csv\": \"df_sr_hex_truncated\",\n",
    "    \"city-hex-polygons-8.geojson\": \"gdf_city_hex_8\"\n",
    "}\n",
    "\n",
    "# Load the files\n",
    "for file_name, var_name in file_map.items():\n",
    "    file_path = DATA_DIR / file_name\n",
    "    logger.info(f\"\\nProcessing {file_path}...\")\n",
    "\n",
    "    if file_path.suffix == \".csv\":\n",
    "        df = pd.read_csv(file_path)\n",
    "        globals()[var_name] = df\n",
    "\n",
    "    elif file_path.suffix == \".geojson\":\n",
    "        gdf = gpd.read_file(file_path)\n",
    "        globals()[var_name] = gdf\n",
    "\n",
    "logger.info(\"All files loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4079940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc, time, logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------- Robust logger setup (no duplicates) -----------------\n",
    "def get_logger(name=\"h3_assign\", level=logging.INFO) -> logging.Logger:\n",
    "    lg = logging.getLogger(name)\n",
    "    lg.setLevel(level)\n",
    "    lg.propagate = False  # stop bubbling to root (prevents duplicate lines)\n",
    "\n",
    "    # Remove existing handlers (safe for re-running in notebooks)\n",
    "    for h in list(lg.handlers):\n",
    "        lg.removeHandler(h)\n",
    "\n",
    "    h = logging.StreamHandler()\n",
    "    h.setLevel(level)\n",
    "    h.setFormatter(logging.Formatter(\n",
    "        \"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n",
    "        datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    ))\n",
    "    lg.addHandler(h)\n",
    "    return lg\n",
    "\n",
    "logger = get_logger(level=logging.INFO)   # set to WARNING/ERROR to quiet logs\n",
    "\n",
    "# ----------------- Optional deps -----------------\n",
    "try:\n",
    "    import psutil\n",
    "except ImportError:\n",
    "    psutil = None\n",
    "\n",
    "try:\n",
    "    import tracemalloc\n",
    "    _TRACEMALLOC_OK = True\n",
    "except ImportError:\n",
    "    tracemalloc = None\n",
    "    _TRACEMALLOC_OK = False\n",
    "\n",
    "try:\n",
    "    import h3\n",
    "    _H3_OK = True\n",
    "except ImportError:\n",
    "    h3 = None\n",
    "    _H3_OK = False\n",
    "\n",
    "\n",
    "# ----------------- Helpers -----------------\n",
    "def _fmt_bytes(n: int) -> str:\n",
    "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\"]:\n",
    "        if n < 1024:\n",
    "            return f\"{n:.1f}{unit}\"\n",
    "        n /= 1024\n",
    "    return f\"{n:.1f}PB\"\n",
    "\n",
    "def _resource_snapshot(note: str = \"\"):\n",
    "    \"\"\"Cheap unless DEBUG; shows RSS/VMS/threads/CPU%/heap/GC.\"\"\"\n",
    "    if not logger.isEnabledFor(logging.DEBUG):\n",
    "        return\n",
    "    parts = []\n",
    "    if psutil:\n",
    "        p = psutil.Process(os.getpid())\n",
    "        mem = p.memory_info()\n",
    "        parts.append(f\"RSS={_fmt_bytes(mem.rss)} VMS={_fmt_bytes(mem.vms)}\")\n",
    "        parts.append(f\"Threads={p.num_threads()} CPU%={p.cpu_percent(interval=None):.1f}\")\n",
    "    if _TRACEMALLOC_OK and tracemalloc.is_tracing():\n",
    "        cur, peak = tracemalloc.get_traced_memory()\n",
    "        parts.append(f\"Heap={_fmt_bytes(cur)}/{_fmt_bytes(peak)}\")\n",
    "    parts.append(f\"GC={gc.get_count()}\")\n",
    "    logger.debug(\"[%s] %s\", note, \"; \".join(parts))\n",
    "\n",
    "\n",
    "# ----------------- Main -----------------\n",
    "def assign_h3_level8(\n",
    "    df: pd.DataFrame,\n",
    "    lat_col: str = \"latitude\",\n",
    "    long_col: str = \"longitude\",\n",
    "    threshold: float = 0.05,\n",
    "    resolution: int = 8,\n",
    "    early_abort: bool = True,\n",
    "    *,\n",
    "    log_validation: bool = True,\n",
    "    log_join: bool = True,\n",
    "    copy_frame: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Assign H3 (v4) hex index at `resolution` to points.\n",
    "\n",
    "    Performance/Logging notes:\n",
    "      • Resource snapshots only in DEBUG level.\n",
    "      • `log_validation` / `log_join` toggle INFO prints.\n",
    "      • Avoids extra O(n) scans by deriving join stats from `valid`.\n",
    "      • Set `copy_frame=False` to mutate the input frame (fastest).\n",
    "    \"\"\"\n",
    "    if not _H3_OK:\n",
    "        raise RuntimeError(\"h3 is not installed\")\n",
    "\n",
    "    if lat_col not in df.columns or long_col not in df.columns:\n",
    "        raise ValueError(f\"Missing required columns: {lat_col}, {long_col}\")\n",
    "\n",
    "    # Enable tracemalloc only if DEBUG\n",
    "    tracing = False\n",
    "    if logger.isEnabledFor(logging.DEBUG) and _TRACEMALLOC_OK:\n",
    "        tracemalloc.start()\n",
    "        tracing = True\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    # Choose frame\n",
    "    df_out = df.copy() if copy_frame else df\n",
    "\n",
    "    # --- Validation ---\n",
    "    lat = pd.to_numeric(df_out[lat_col], errors=\"coerce\").to_numpy()\n",
    "    lon = pd.to_numeric(df_out[long_col], errors=\"coerce\").to_numpy()\n",
    "    valid = (\n",
    "        np.isfinite(lat) & np.isfinite(lon) &\n",
    "        (lat >= -90.0) & (lat <= 90.0) &\n",
    "        (lon >= -180.0) & (lon <= 180.0)\n",
    "    )\n",
    "    n = int(lat.shape[0])\n",
    "    n_valid = int(valid.sum())\n",
    "    n_invalid = n - n_valid\n",
    "    fail_rate_pre = (n_invalid / n) if n else 0.0\n",
    "\n",
    "    if log_validation:\n",
    "        logger.info(\"Validation: rows=%d invalid=%d (%.2f%%)\", n, n_invalid, fail_rate_pre * 100)\n",
    "\n",
    "    if early_abort and fail_rate_pre > threshold:\n",
    "        if tracing:\n",
    "            tracemalloc.stop()\n",
    "        raise RuntimeError(\n",
    "            f\"Failure rate {fail_rate_pre:.2%} exceeds threshold {threshold:.2%}\"\n",
    "        )\n",
    "\n",
    "    # --- Compute H3 (object dtype; switch to uint64 in future if you want max speed) ---\n",
    "    out = np.full(n, \"0\", dtype=object)\n",
    "    if n_valid:\n",
    "        out[valid] = [\n",
    "            h3.latlng_to_cell(la, lo, resolution)\n",
    "            for la, lo in zip(lat[valid], lon[valid])\n",
    "        ]\n",
    "\n",
    "    # Assign without extra copy\n",
    "    df_out[\"h3_level8_index\"] = out\n",
    "\n",
    "    # --- Join stats from 'valid' (no rescan of out) ---\n",
    "    success = n_valid\n",
    "    failed = n_invalid\n",
    "    failed_rate = (failed / n) if n else 0.0\n",
    "\n",
    "    if log_join:\n",
    "        logger.info(\"Join stats: success=%d failed=%d (%.2f%%)\", success, failed, failed_rate * 100)\n",
    "\n",
    "    if n and failed_rate > threshold:\n",
    "        if tracing:\n",
    "            tracemalloc.stop()\n",
    "        raise RuntimeError(\"Too many failed joins\")\n",
    "\n",
    "    # Done\n",
    "    logger.info(\"Total elapsed: %.3fs\", time.perf_counter() - t0)\n",
    "    _resource_snapshot(\"end\")\n",
    "\n",
    "    if tracing:\n",
    "        tracemalloc.stop()\n",
    "\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdba7e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 21:30:14 | INFO     | Validation: rows=1 invalid=0 (0.00%)\n",
      "2025-08-19 21:30:14 | INFO     | Join stats: success=1 failed=0 (0.00%)\n",
      "2025-08-19 21:30:14 | INFO     | Total elapsed: 0.001s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 21:30:15 | INFO     | Validation: rows=1 invalid=0 (0.00%)\n",
      "2025-08-19 21:30:15 | INFO     | Join stats: success=1 failed=0 (0.00%)\n",
      "2025-08-19 21:30:15 | INFO     | Total elapsed: 0.001s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 21:30:15 | INFO     | Validation: rows=1 invalid=1 (100.00%)\n",
      "2025-08-19 21:30:15 | INFO     | Join stats: success=0 failed=1 (100.00%)\n",
      "2025-08-19 21:30:15 | INFO     | Total elapsed: 0.001s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 21:30:15 | INFO     | Validation: rows=1 invalid=1 (100.00%)\n",
      "2025-08-19 21:30:15 | INFO     | Join stats: success=0 failed=1 (100.00%)\n",
      "2025-08-19 21:30:15 | INFO     | Total elapsed: 0.001s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 21:30:15 | INFO     | Validation: rows=1 invalid=1 (100.00%)\n",
      "2025-08-19 21:30:15 | INFO     | Join stats: success=0 failed=1 (100.00%)\n",
      "2025-08-19 21:30:15 | INFO     | Total elapsed: 0.001s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 21:30:15 | INFO     | Validation: rows=1 invalid=1 (100.00%)\n",
      "2025-08-19 21:30:15 | INFO     | Join stats: success=0 failed=1 (100.00%)\n",
      "2025-08-19 21:30:15 | INFO     | Total elapsed: 0.001s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 21:30:15 | INFO     | Validation: rows=3 invalid=3 (100.00%)\n",
      "2025-08-19 21:30:15 | INFO     | Join stats: success=0 failed=3 (100.00%)\n",
      "2025-08-19 21:30:15 | INFO     | Total elapsed: 0.001s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 21:30:15 | INFO     | Validation: rows=2 invalid=1 (50.00%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 21:30:15 | INFO     | Validation: rows=1 invalid=0 (0.00%)\n",
      "2025-08-19 21:30:15 | INFO     | Join stats: success=1 failed=0 (0.00%)\n",
      "2025-08-19 21:30:15 | INFO     | Total elapsed: 0.001s\n",
      "2025-08-19 21:30:15 | INFO     | Validation: rows=1 invalid=0 (0.00%)\n",
      "2025-08-19 21:30:15 | INFO     | Join stats: success=1 failed=0 (0.00%)\n",
      "2025-08-19 21:30:15 | INFO     | Total elapsed: 0.001s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                   [100%]\u001b[0m\n",
      "============================================== PASSES ==============================================\n",
      "\u001b[32m\u001b[1m_________________________________ test_valid_coords_return_h3_cell _________________________________\u001b[0m\n",
      "---------------------------------------- Captured log call -----------------------------------------\n",
      "\u001b[32mINFO    \u001b[0m __main__:2886585605.py:80 Validation: rows=1 invalid=0 (0.00%)\n",
      "\u001b[32mINFO    \u001b[0m __main__:2886585605.py:94 Join stats: success=1 failed=0 (0.00%)\n",
      "\u001b[32mINFO    \u001b[0m __main__:2886585605.py:99 Total elapsed: 0.001s\n",
      "\u001b[32m\u001b[1m_______________________________ test_known_point_exact_index_level8 ________________________________\u001b[0m\n",
      "---------------------------------------- Captured log call -----------------------------------------\n",
      "\u001b[32mINFO    \u001b[0m __main__:2886585605.py:80 Validation: rows=1 invalid=0 (0.00%)\n",
      "\u001b[32mINFO    \u001b[0m __main__:2886585605.py:94 Join stats: success=1 failed=0 (0.00%)\n",
      "\u001b[32mINFO    \u001b[0m __main__:2886585605.py:99 Total elapsed: 0.001s\n",
      "\u001b[32m\u001b[1m___________________________ test_nan_lat_or_lon_produces_zero[nan-18.4] ____________________________\u001b[0m\n",
      "---------------------------------------- Captured log call -----------------------------------------\n",
      "\u001b[32mINFO    \u001b[0m __main__:2886585605.py:80 Validation: rows=1 invalid=1 (100.00%)\n",
      "\u001b[32mINFO    \u001b[0m __main__:2886585605.py:94 Join stats: success=0 failed=1 (100.00%)\n",
      "\u001b[32mINFO    \u001b[0m __main__:2886585605.py:99 Total elapsed: 0.001s\n",
      "\u001b[32m\u001b[1m___________________________ test_nan_lat_or_lon_produces_zero[-33.9-nan] ___________________________\u001b[0m\n",
      "---------------------------------------- Captured log call -----------------------------------------\n",
      "\u001b[32mINFO    \u001b[0m __main__:2886585605.py:80 Validation: rows=1 invalid=1 (100.00%)\n",
      "\u001b[32mINFO    \u001b[0m __main__:2886585605.py:94 Join stats: success=0 failed=1 (100.00%)\n",
      "\u001b[32mINFO    \u001b[0m __main__:2886585605.py:99 Total elapsed: 0.001s\n",
      "\u001b[32m\u001b[1m___________________________ test_nan_lat_or_lon_produces_zero[None-18.4] ___________________________\u001b[0m\n",
      "---------------------------------------- Captured log call -----------------------------------------\n",
      "\u001b[32mINFO    \u001b[0m __main__:2886585605.py:80 Validation: rows=1 invalid=1 (100.00%)\n",
      "\u001b[32mINFO    \u001b[0m __main__:2886585605.py:94 Join stats: success=0 failed=1 (100.00%)\n",
      "\u001b[32mINFO    \u001b[0m __main__:2886585605.py:99 Total elapsed: 0.001s\n",
      "\u001b[32m\u001b[1m__________________________ test_nan_lat_or_lon_produces_zero[-33.9-None] ___________________________\u001b[0m\n",
      "---------------------------------------- Captured log call -----------------------------------------\n",
      "\u001b[32mINFO    \u001b[0m __main__:2886585605.py:80 Validation: rows=1 invalid=1 (100.00%)\n",
      "\u001b[32mINFO    \u001b[0m __main__:2886585605.py:94 Join stats: success=0 failed=1 (100.00%)\n",
      "\u001b[32mINFO    \u001b[0m __main__:2886585605.py:99 Total elapsed: 0.001s\n",
      "\u001b[32m\u001b[1m______________________________ test_out_of_range_coords_produce_zero _______________________________\u001b[0m\n",
      "---------------------------------------- Captured log call -----------------------------------------\n",
      "\u001b[32mINFO    \u001b[0m __main__:2886585605.py:80 Validation: rows=3 invalid=3 (100.00%)\n",
      "\u001b[32mINFO    \u001b[0m __main__:2886585605.py:94 Join stats: success=0 failed=3 (100.00%)\n",
      "\u001b[32mINFO    \u001b[0m __main__:2886585605.py:99 Total elapsed: 0.001s\n",
      "\u001b[32m\u001b[1m_________________________ test_precheck_early_abort_on_high_invalid_ratio __________________________\u001b[0m\n",
      "---------------------------------------- Captured log call -----------------------------------------\n",
      "\u001b[32mINFO    \u001b[0m __main__:2886585605.py:80 Validation: rows=2 invalid=1 (50.00%)\n",
      "\u001b[32m\u001b[1m__________________________________ test_resolution_changes_output __________________________________\u001b[0m\n",
      "---------------------------------------- Captured log call -----------------------------------------\n",
      "\u001b[32mINFO    \u001b[0m __main__:2886585605.py:80 Validation: rows=1 invalid=0 (0.00%)\n",
      "\u001b[32mINFO    \u001b[0m __main__:2886585605.py:94 Join stats: success=1 failed=0 (0.00%)\n",
      "\u001b[32mINFO    \u001b[0m __main__:2886585605.py:99 Total elapsed: 0.001s\n",
      "\u001b[32mINFO    \u001b[0m __main__:2886585605.py:80 Validation: rows=1 invalid=0 (0.00%)\n",
      "\u001b[32mINFO    \u001b[0m __main__:2886585605.py:94 Join stats: success=1 failed=0 (0.00%)\n",
      "\u001b[32mINFO    \u001b[0m __main__:2886585605.py:99 Total elapsed: 0.001s\n",
      "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
      "\u001b[32mPASSED\u001b[0m t_c4f6ff3f44df4253b0daab572f523d3f.py::\u001b[1mtest_valid_coords_return_h3_cell\u001b[0m\n",
      "\u001b[32mPASSED\u001b[0m t_c4f6ff3f44df4253b0daab572f523d3f.py::\u001b[1mtest_known_point_exact_index_level8\u001b[0m\n",
      "\u001b[32mPASSED\u001b[0m t_c4f6ff3f44df4253b0daab572f523d3f.py::\u001b[1mtest_nan_lat_or_lon_produces_zero[nan-18.4]\u001b[0m\n",
      "\u001b[32mPASSED\u001b[0m t_c4f6ff3f44df4253b0daab572f523d3f.py::\u001b[1mtest_nan_lat_or_lon_produces_zero[-33.9-nan]\u001b[0m\n",
      "\u001b[32mPASSED\u001b[0m t_c4f6ff3f44df4253b0daab572f523d3f.py::\u001b[1mtest_nan_lat_or_lon_produces_zero[None-18.4]\u001b[0m\n",
      "\u001b[32mPASSED\u001b[0m t_c4f6ff3f44df4253b0daab572f523d3f.py::\u001b[1mtest_nan_lat_or_lon_produces_zero[-33.9-None]\u001b[0m\n",
      "\u001b[32mPASSED\u001b[0m t_c4f6ff3f44df4253b0daab572f523d3f.py::\u001b[1mtest_out_of_range_coords_produce_zero\u001b[0m\n",
      "\u001b[32mPASSED\u001b[0m t_c4f6ff3f44df4253b0daab572f523d3f.py::\u001b[1mtest_precheck_early_abort_on_high_invalid_ratio\u001b[0m\n",
      "\u001b[32mPASSED\u001b[0m t_c4f6ff3f44df4253b0daab572f523d3f.py::\u001b[1mtest_resolution_changes_output\u001b[0m\n",
      "\u001b[32mPASSED\u001b[0m t_c4f6ff3f44df4253b0daab572f523d3f.py::\u001b[1mtest_missing_columns_raise_value_error\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest -q -rA\n",
    "import __main__ as nb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytest\n",
    "\n",
    "# --- Make sure the notebook-defined function sees required globals ---\n",
    "def _wire_globals_for_notebook_func():\n",
    "    fn = nb.assign_h3_level8\n",
    "\n",
    "    # Provide pandas if not in function globals\n",
    "    if \"pd\" not in fn.__globals__:\n",
    "        fn.__globals__[\"pd\"] = pd\n",
    "\n",
    "    # Lightweight logger stub\n",
    "    class _Logger:\n",
    "        def debug(self, *a, **k): pass\n",
    "        def info(self, *a, **k): pass\n",
    "        def error(self, *a, **k): pass\n",
    "\n",
    "    if \"logger\" not in fn.__globals__:\n",
    "        fn.__globals__[\"logger\"] = _Logger()\n",
    "\n",
    "    \n",
    "    if \"error\" not in fn.__globals__:\n",
    "        fn.__globals__[\"error\"] = lambda *a, **k: None\n",
    "\n",
    "_wire_globals_for_notebook_func()\n",
    "\n",
    "# Use real h3 if available; otherwise skip these tests cleanly\n",
    "h3 = pytest.importorskip(\"h3\")\n",
    "\n",
    "def test_valid_coords_return_h3_cell():\n",
    "    df = pd.DataFrame({\"latitude\": [-33.9249], \"longitude\": [18.4241]})\n",
    "    out = nb.assign_h3_level8(df, resolution=8, threshold=0.0, early_abort=False)\n",
    "    assert out.loc[0, \"h3_level8_index\"] == h3.latlng_to_cell(-33.9249, 18.4241, 8)\n",
    "    \n",
    "def test_known_point_exact_index_level8():\n",
    "    lat, lon = -33.872839, 18.522488\n",
    "    expected = \"88ad360225fffff\"\n",
    "    df = pd.DataFrame({\"latitude\": [lat], \"longitude\": [lon]})\n",
    "    out = nb.assign_h3_level8(df, resolution=8, threshold=0.0, early_abort=False)\n",
    "    assert out.loc[0, \"h3_level8_index\"] == expected\n",
    "\n",
    "\n",
    "@pytest.mark.parametrize(\"lat,lon\", [\n",
    "    (np.nan, 18.4),      \n",
    "    (-33.9, np.nan),     \n",
    "    (None, 18.4),        \n",
    "    (-33.9, None),       \n",
    "])\n",
    "def test_nan_lat_or_lon_produces_zero(lat, lon):\n",
    "    df = pd.DataFrame({\"latitude\": [lat], \"longitude\": [lon]})\n",
    "    out = nb.assign_h3_level8(df, threshold=1.0, early_abort=False)  \n",
    "    assert out.loc[0, \"h3_level8_index\"] == \"0\"\n",
    "\n",
    "def test_out_of_range_coords_produce_zero():\n",
    "    df = pd.DataFrame({\n",
    "        \"latitude\":  [-91.0,  0.0,   45.0],\n",
    "        \"longitude\": [  0.0, 200.0,  np.nan],\n",
    "    })\n",
    "    out = nb.assign_h3_level8(df, threshold=1.0, early_abort=False)\n",
    "    assert out[\"h3_level8_index\"].tolist() == [\"0\", \"0\", \"0\"]\n",
    "\n",
    "def test_precheck_early_abort_on_high_invalid_ratio():\n",
    "    \n",
    "    df = pd.DataFrame({\"latitude\": [100.0, -33.9], \"longitude\": [0.0, 18.4]})\n",
    "    with pytest.raises(RuntimeError, match=\"exceeds threshold\"):\n",
    "        nb.assign_h3_level8(df, threshold=0.4, early_abort=True)\n",
    "\n",
    "def test_resolution_changes_output():\n",
    "    df = pd.DataFrame({\"latitude\": [-33.9249], \"longitude\": [18.4241]})\n",
    "    out7 = nb.assign_h3_level8(df, resolution=7, threshold=0.0, early_abort=False)\n",
    "    out8 = nb.assign_h3_level8(df, resolution=8, threshold=0.0, early_abort=False)\n",
    "    assert out7.loc[0, \"h3_level8_index\"] != out8.loc[0, \"h3_level8_index\"]\n",
    "\n",
    "def test_missing_columns_raise_value_error():\n",
    "    df = pd.DataFrame({\"latitude\": [0.0]})  \n",
    "    with pytest.raises(ValueError):\n",
    "        nb.assign_h3_level8(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dc6bb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compare_h3_by_notification(\n",
    "    df1: pd.DataFrame,\n",
    "    df2: pd.DataFrame,\n",
    "    key: str = \"notification_number\",\n",
    "    col: str = \"h3_level8_index\",\n",
    "    coerce_to_str: bool = True,   # normalize dtypes before compare\n",
    "    na_equal: bool = True,        # treat NaN==NaN as equal\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare df1 vs df2 on a single column (h3_level8_index) by notification key.\n",
    "\n",
    "    Returns dict with:\n",
    "      - only_in_df1: keys present only in df1\n",
    "      - only_in_df2: keys present only in df2\n",
    "      - matches: keys in both where h3 matches (per na_equal rule)\n",
    "      - mismatches: keys in both where h3 differs, with left/right values\n",
    "    \"\"\"\n",
    "    if key not in df1.columns or key not in df2.columns:\n",
    "        raise ValueError(f\"Key '{key}' must exist in both DataFrames.\")\n",
    "    if col not in df1.columns or col not in df2.columns:\n",
    "        raise ValueError(f\"Column '{col}' must exist in both DataFrames.\")\n",
    "\n",
    "    left = df1[[key, col]].copy()\n",
    "    right = df2[[key, col]].copy()\n",
    "\n",
    "    if coerce_to_str:\n",
    "        for d in (left, right):\n",
    "            d[col] = d[col].astype(\"object\").where(d[col].isna(), d[col].astype(str))\n",
    "\n",
    "    merged = left.merge(\n",
    "        right,\n",
    "        on=key,\n",
    "        how=\"outer\",\n",
    "        suffixes=(\"_df1\", \"_df2\"),\n",
    "        indicator=True,\n",
    "    )\n",
    "\n",
    "    only_in_df1 = merged.loc[merged[\"_merge\"] == \"left_only\", [key]]\n",
    "    only_in_df2 = merged.loc[merged[\"_merge\"] == \"right_only\", [key]]\n",
    "\n",
    "    both = merged.loc[merged[\"_merge\"] == \"both\", [key, f\"{col}_df1\", f\"{col}_df2\"]].copy()\n",
    "\n",
    "    lv = both[f\"{col}_df1\"]\n",
    "    rv = both[f\"{col}_df2\"]\n",
    "    equal_mask = (lv == rv)\n",
    "    if na_equal:\n",
    "        equal_mask = equal_mask | (lv.isna() & rv.isna())\n",
    "\n",
    "    matches = both.loc[equal_mask, [key]]\n",
    "    mismatches = both.loc[~equal_mask, [key, f\"{col}_df1\", f\"{col}_df2\"]].rename(\n",
    "        columns={f\"{col}_df1\": f\"{col}_left\", f\"{col}_df2\": f\"{col}_right\"}\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"only_in_df1\": only_in_df1.reset_index(drop=True),\n",
    "        \"only_in_df2\": only_in_df2.reset_index(drop=True),\n",
    "        \"matches\": matches.reset_index(drop=True),\n",
    "        \"mismatches\": mismatches.reset_index(drop=True),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225f600f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 21:33:48 | INFO | h3_assign | Validation: rows=941634 invalid=212364 (22.55%)\n",
      "2025-08-19 21:33:48 | INFO | h3_assign | Total elapsed: 0.423s\n",
      "2025-08-19 21:33:48 | INFO | h3_assign | Validation: rows=941634 invalid=212364 (22.55%)\n",
      "2025-08-19 21:33:49 | INFO | h3_assign | Total elapsed: 0.581s\n"
     ]
    }
   ],
   "source": [
    "df_sr2 = assign_h3_level8(df_sr, lat_col=\"latitude\", long_col=\"longitude\", threshold=0.226, copy_frame=False, log_join=False)\n",
    "df_sr2.drop(columns=[\"Unnamed: 0\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa36842",
   "metadata": {},
   "source": [
    "Threshold was chosen at 22.6% as 22.55% failed to join. Thus I chose a higher threshold so that the code would not fail early. The default if we don't set a threshold is 5% as this would give us a confidence level of 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a5341da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only in df1: 0\n",
      "Only in df2: 0\n",
      "Matches    : 941634\n",
      "Mismatches : 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "result = compare_h3_by_notification(df_sr2, df_sr_hex, key=\"notification_number\", col=\"h3_level8_index\")\n",
    "\n",
    "print(\"Only in df1:\", len(result[\"only_in_df1\"]))\n",
    "print(\"Only in df2:\", len(result[\"only_in_df2\"]))\n",
    "print(\"Matches    :\", len(result[\"matches\"]))\n",
    "print(\"Mismatches :\", len(result[\"mismatches\"]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
